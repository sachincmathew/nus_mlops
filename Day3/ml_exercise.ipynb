{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-On Activity: Wine Quality Prediction using Random Forest Regression\n",
    "--- \n",
    "### Introduction:\n",
    "\n",
    "In this hands-on activity, you will work with the Wine Quality dataset to build a Random Forest Regression model to predict the quality of wine based on various features. The quality score ranges from 0 to 10, with higher scores indicating better wine quality.\n",
    "\n",
    "### Task Overview:\n",
    "\n",
    "1. **Data Loading and Exploration:**\n",
    "   - Import the necessary libraries (already provided in the code).\n",
    "   - Load the Wine Quality dataset using `load_wine()` and create a Pandas DataFrame.\n",
    "   - Inspect the first few rows of the DataFrame to understand the data.\n",
    "\n",
    "2. **Dataset Information:**\n",
    "   - Check the information about the dataset using `df.info()`.\n",
    "\n",
    "3. **Data Splitting and Standardization:**\n",
    "   - Separate features (X) and the target variable (y).\n",
    "   - Split the data into training and testing sets (use `train_test_split` with a test size of 20% and `random_state` of 42).\n",
    "   - Standardize the features using `StandardScaler`.\n",
    "\n",
    "4. **Random Forest Regression:**\n",
    "   - Define a Random Forest Regressor model with `random_state` set to 42.\n",
    "   - Perform hyperparameter tuning using `GridSearchCV` with the following parameter grid:\n",
    "     - `n_estimators`: [50, 100, 200]\n",
    "     - `max_depth`: [None, 10, 20]\n",
    "\n",
    "5. **Model Evaluation:**\n",
    "   - Print the best hyperparameters obtained from the grid search.\n",
    "   - Use the best model to make predictions on the test set.\n",
    "   - Evaluate the model performance using the R-squared (`r2_score`) on the test set.\n",
    "   - Display the results.\n",
    "\n",
    "### Additional Guidelines:\n",
    "- Follow the provided code structure and fill in the necessary code to complete each task.\n",
    "\n",
    "Enjoy the hands-on experience, and good luck with your wine quality prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  target  \n",
       "0                          3.92   1065.0       0  \n",
       "1                          3.40   1050.0       0  \n",
       "2                          3.17   1185.0       0  \n",
       "3                          3.45   1480.0       0  \n",
       "4                          2.93    735.0       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Wine Quality dataset\n",
    "wine_data = load_wine()\n",
    "\n",
    "# Create a Pandas DataFrame from the dataset\n",
    "df = pd.DataFrame(wine_data.data, columns=wine_data.feature_names)\n",
    "\n",
    "# Add the target values to the DataFrame as a new column\n",
    "df[\"target\"] = wine_data.target\n",
    "\n",
    "# Inspect the first few rows of the DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 14 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   alcohol                       178 non-null    float64\n",
      " 1   malic_acid                    178 non-null    float64\n",
      " 2   ash                           178 non-null    float64\n",
      " 3   alcalinity_of_ash             178 non-null    float64\n",
      " 4   magnesium                     178 non-null    float64\n",
      " 5   total_phenols                 178 non-null    float64\n",
      " 6   flavanoids                    178 non-null    float64\n",
      " 7   nonflavanoid_phenols          178 non-null    float64\n",
      " 8   proanthocyanins               178 non-null    float64\n",
      " 9   color_intensity               178 non-null    float64\n",
      " 10  hue                           178 non-null    float64\n",
      " 11  od280/od315_of_diluted_wines  178 non-null    float64\n",
      " 12  proline                       178 non-null    float64\n",
      " 13  target                        178 non-null    int32  \n",
      "dtypes: float64(13), int32(1)\n",
      "memory usage: 18.9 KB\n"
     ]
    }
   ],
   "source": [
    "# Check the information about the dataset\n",
    "df.info()\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df.drop(\"target\", axis=1)\n",
    "y = df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1.665293</td>\n",
       "      <td>-0.608406</td>\n",
       "      <td>1.218962</td>\n",
       "      <td>1.605400</td>\n",
       "      <td>-0.167384</td>\n",
       "      <td>0.804002</td>\n",
       "      <td>-0.691678</td>\n",
       "      <td>1.267226</td>\n",
       "      <td>1.877540</td>\n",
       "      <td>3.419473</td>\n",
       "      <td>-1.656329</td>\n",
       "      <td>-0.879409</td>\n",
       "      <td>-0.248606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>-0.549525</td>\n",
       "      <td>2.751541</td>\n",
       "      <td>1.003315</td>\n",
       "      <td>1.605400</td>\n",
       "      <td>-0.304379</td>\n",
       "      <td>-0.785384</td>\n",
       "      <td>-1.401233</td>\n",
       "      <td>2.049600</td>\n",
       "      <td>-0.873505</td>\n",
       "      <td>-0.024801</td>\n",
       "      <td>-0.584633</td>\n",
       "      <td>-1.254621</td>\n",
       "      <td>-0.729922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.745310</td>\n",
       "      <td>-1.143541</td>\n",
       "      <td>-0.937507</td>\n",
       "      <td>-0.282704</td>\n",
       "      <td>-0.852357</td>\n",
       "      <td>1.937029</td>\n",
       "      <td>1.746791</td>\n",
       "      <td>-1.001659</td>\n",
       "      <td>0.587987</td>\n",
       "      <td>-0.240068</td>\n",
       "      <td>0.358460</td>\n",
       "      <td>0.246227</td>\n",
       "      <td>-0.248606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.612948</td>\n",
       "      <td>-0.617179</td>\n",
       "      <td>1.003315</td>\n",
       "      <td>0.879206</td>\n",
       "      <td>-0.783860</td>\n",
       "      <td>0.489272</td>\n",
       "      <td>-0.901547</td>\n",
       "      <td>1.188988</td>\n",
       "      <td>1.172585</td>\n",
       "      <td>2.881305</td>\n",
       "      <td>-1.656329</td>\n",
       "      <td>-1.129550</td>\n",
       "      <td>-0.381383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.111249</td>\n",
       "      <td>-0.766315</td>\n",
       "      <td>-0.937507</td>\n",
       "      <td>-1.154137</td>\n",
       "      <td>-0.167384</td>\n",
       "      <td>0.174542</td>\n",
       "      <td>0.637487</td>\n",
       "      <td>-0.688710</td>\n",
       "      <td>-0.409266</td>\n",
       "      <td>-0.584496</td>\n",
       "      <td>0.958609</td>\n",
       "      <td>0.135053</td>\n",
       "      <td>0.946386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1.077938</td>\n",
       "      <td>-0.757542</td>\n",
       "      <td>1.111138</td>\n",
       "      <td>1.605400</td>\n",
       "      <td>-0.989352</td>\n",
       "      <td>1.040049</td>\n",
       "      <td>0.857349</td>\n",
       "      <td>-1.236371</td>\n",
       "      <td>0.450435</td>\n",
       "      <td>-0.722267</td>\n",
       "      <td>1.730230</td>\n",
       "      <td>0.788199</td>\n",
       "      <td>-1.078462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>-0.892149</td>\n",
       "      <td>-0.564542</td>\n",
       "      <td>-0.865625</td>\n",
       "      <td>-0.137465</td>\n",
       "      <td>-1.400336</td>\n",
       "      <td>-1.005695</td>\n",
       "      <td>0.027870</td>\n",
       "      <td>0.015427</td>\n",
       "      <td>0.037778</td>\n",
       "      <td>-0.713656</td>\n",
       "      <td>0.186988</td>\n",
       "      <td>0.802096</td>\n",
       "      <td>-0.746519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.714239</td>\n",
       "      <td>-0.441724</td>\n",
       "      <td>0.068845</td>\n",
       "      <td>-2.170809</td>\n",
       "      <td>0.106605</td>\n",
       "      <td>1.590826</td>\n",
       "      <td>1.636860</td>\n",
       "      <td>-0.610472</td>\n",
       "      <td>2.324585</td>\n",
       "      <td>1.051535</td>\n",
       "      <td>1.044345</td>\n",
       "      <td>0.565852</td>\n",
       "      <td>2.695722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>-0.353740</td>\n",
       "      <td>-0.739996</td>\n",
       "      <td>-0.362449</td>\n",
       "      <td>0.356346</td>\n",
       "      <td>-1.400336</td>\n",
       "      <td>-1.430580</td>\n",
       "      <td>-0.541773</td>\n",
       "      <td>1.658413</td>\n",
       "      <td>0.020584</td>\n",
       "      <td>-0.864343</td>\n",
       "      <td>0.015517</td>\n",
       "      <td>-0.740442</td>\n",
       "      <td>-0.796311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>-0.782020</td>\n",
       "      <td>0.067093</td>\n",
       "      <td>0.356374</td>\n",
       "      <td>0.443490</td>\n",
       "      <td>-0.167384</td>\n",
       "      <td>0.426326</td>\n",
       "      <td>0.107820</td>\n",
       "      <td>-0.219285</td>\n",
       "      <td>-0.512431</td>\n",
       "      <td>-0.971977</td>\n",
       "      <td>-0.670368</td>\n",
       "      <td>1.093928</td>\n",
       "      <td>-0.985518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      alcohol  malic_acid       ash  alcalinity_of_ash  magnesium  \\\n",
       "158  1.665293   -0.608406  1.218962           1.605400  -0.167384   \n",
       "137 -0.549525    2.751541  1.003315           1.605400  -0.304379   \n",
       "98  -0.745310   -1.143541 -0.937507          -0.282704  -0.852357   \n",
       "159  0.612948   -0.617179  1.003315           0.879206  -0.783860   \n",
       "38   0.111249   -0.766315 -0.937507          -1.154137  -0.167384   \n",
       "..        ...         ...       ...                ...        ...   \n",
       "71   1.077938   -0.757542  1.111138           1.605400  -0.989352   \n",
       "106 -0.892149   -0.564542 -0.865625          -0.137465  -1.400336   \n",
       "14   1.714239   -0.441724  0.068845          -2.170809   0.106605   \n",
       "92  -0.353740   -0.739996 -0.362449           0.356346  -1.400336   \n",
       "102 -0.782020    0.067093  0.356374           0.443490  -0.167384   \n",
       "\n",
       "     total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
       "158       0.804002   -0.691678              1.267226         1.877540   \n",
       "137      -0.785384   -1.401233              2.049600        -0.873505   \n",
       "98        1.937029    1.746791             -1.001659         0.587987   \n",
       "159       0.489272   -0.901547              1.188988         1.172585   \n",
       "38        0.174542    0.637487             -0.688710        -0.409266   \n",
       "..             ...         ...                   ...              ...   \n",
       "71        1.040049    0.857349             -1.236371         0.450435   \n",
       "106      -1.005695    0.027870              0.015427         0.037778   \n",
       "14        1.590826    1.636860             -0.610472         2.324585   \n",
       "92       -1.430580   -0.541773              1.658413         0.020584   \n",
       "102       0.426326    0.107820             -0.219285        -0.512431   \n",
       "\n",
       "     color_intensity       hue  od280/od315_of_diluted_wines   proline  \n",
       "158         3.419473 -1.656329                     -0.879409 -0.248606  \n",
       "137        -0.024801 -0.584633                     -1.254621 -0.729922  \n",
       "98         -0.240068  0.358460                      0.246227 -0.248606  \n",
       "159         2.881305 -1.656329                     -1.129550 -0.381383  \n",
       "38         -0.584496  0.958609                      0.135053  0.946386  \n",
       "..               ...       ...                           ...       ...  \n",
       "71         -0.722267  1.730230                      0.788199 -1.078462  \n",
       "106        -0.713656  0.186988                      0.802096 -0.746519  \n",
       "14          1.051535  1.044345                      0.565852  2.695722  \n",
       "92         -0.864343  0.015517                     -0.740442 -0.796311  \n",
       "102        -0.971977 -0.670368                      1.093928 -0.985518  \n",
       "\n",
       "[142 rows x 13 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize the features using StandardScaler\n",
    "numerical_columns = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply standard scaling to selected columns\n",
    "X_train[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])\n",
    "X_test[numerical_columns] = scaler.fit_transform(X_test[numerical_columns])\n",
    "# Display the scaled dataset\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the Random Forest Regressor model with random_state\n",
    "# rf_model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# # Hyperparameter tuning with GridSearchCV\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200, 300, 500],  # Specify a list of values to try for the number of trees\n",
    "#     'max_depth': [None, 10, 20]  # Specify the maximum depth of the trees or use None for unlimited depth\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, scoring='r2', cv=5, n_jobs=-1)\n",
    "# grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "# Define the Random Forest Regressor model with random_state\n",
    "rf_model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "param_space = {\n",
    "    'n_estimators': Integer(50, 500),  # Number of trees\n",
    "    'max_depth': Integer(1, 20)  # Maximum depth of the trees\n",
    "}\n",
    "\n",
    "# Perform Bayesian optimization\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=rf_model,\n",
    "    search_spaces=param_space,\n",
    "    scoring='r2',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "bayes_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Best hyperparameters\n",
    "# best_params = grid_search.best_params_\n",
    "# best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# # Predictions on the test set\n",
    "# y_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# # Model evaluation\n",
    "# r2 = r2_score(y_test,y_pred)\n",
    "\n",
    "# # Display the results\n",
    "# print(f\"\\nBest Hyperparameters: {best_params}\")\n",
    "# print(f\"R-squared (r2) on Test Set: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters: OrderedDict({'max_depth': 10, 'n_estimators': 292})\n",
      "R-squared (r2) on Test Set: 0.9415\n"
     ]
    }
   ],
   "source": [
    "# Best hyperparameters\n",
    "best_params = bayes_search.best_params_\n",
    "best_rf_model = bayes_search.best_estimator_\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "\n",
    "# Display the results\n",
    "print(f\"\\nBest Hyperparameters: {best_params}\")\n",
    "print(f\"R-squared (r2) on Test Set: {r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
